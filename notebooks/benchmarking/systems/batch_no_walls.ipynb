{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('/rds/general/user/tla19/home/FYP/MAax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Tuple\n",
    "from functools import partial\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldgen import Floor, WorldBuilder, WorldParams\n",
    "from brax.envs.env import State\n",
    "from maax.modules.agents import Agents\n",
    "from maax.modules.walls import RandomWalls, WallScenarios\n",
    "from maax.modules.world import FloorAttributes, WorldConstants\n",
    "from maax.modules.objects import Boxes, Ramps\n",
    "from maax.modules.util import uniform_placement, centre_placement\n",
    "from maax.envs.hide_and_seek import quad_placement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brax\n",
    "import numpy as np\n",
    "from brax.io import mjcf, html\n",
    "from maax.envs.base import Base\n",
    "from maax.util.types import RNGKey, PipelineState, Action\n",
    "from brax.generalized import pipeline\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "from jax import random\n",
    "\n",
    "from IPython.display import HTML, clear_output\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "batch_sizes = [2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "episode_length = 1000\n",
    "random_key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(n_frames=1, horizon=80, deterministic_mode=False,\n",
    "             floor_size=6.0, grid_size=30, door_size=2,\n",
    "             n_hiders=2, n_seekers=2, max_n_agents=None,\n",
    "             n_boxes=1, n_ramps=1, n_elongated_boxes=0,\n",
    "             rand_num_elongated_boxes=False, n_min_boxes=None,\n",
    "             box_size=0.5, boxid_obs=True, boxsize_obs=True, box_only_z_rot=True,\n",
    "             pad_ramp_size=True,\n",
    "             rew_type='joint_zero_sum',\n",
    "             lock_box=True, grab_box=True, lock_ramp=True,\n",
    "             lock_type='any_lock_specific',\n",
    "             lock_grab_radius=0.25, lock_out_of_vision=True, grab_exclusive=False,\n",
    "             grab_out_of_vision=False, grab_selective=False,\n",
    "             box_floor_friction=0.2, other_friction=0.01, gravity=[0, 0, -50],\n",
    "             action_lims=(-0.9, 0.9), polar_obs=True,\n",
    "             scenario='quad', quad_game_hider_uniform_placement=False,\n",
    "             p_door_dropout=0.0,\n",
    "             n_rooms=4, random_room_count=True, prob_outside_walls=1.0,\n",
    "             n_lidar_per_agent=0, visualize_lidar=False, compress_lidar_scale=None,\n",
    "             hiders_together_radius=None, seekers_together_radius=None,\n",
    "             prep_fraction=0.4, prep_rem=False,\n",
    "             team_size_obs=False,\n",
    "             restrict_rect=None, penalize_objects_out=False,\n",
    "             ):\n",
    "    '''\n",
    "        This make_env function is not used anywhere; it exists to provide a simple, bare-bones\n",
    "        example of how to construct a multi-agent environment using the modules framework.\n",
    "    '''\n",
    "    n_agents = n_seekers + n_hiders\n",
    "    env = Base(n_agents=n_agents, n_frames=n_frames, horizon=horizon, grid_size=grid_size,\n",
    "               deterministic_mode=deterministic_mode, seed=seed)\n",
    "#     env.add_module(WallScenarios(grid_size=grid_size, door_size=door_size,\n",
    "#                                      scenario=scenario, friction=other_friction,\n",
    "#                                      p_door_dropout=p_door_dropout))\n",
    "    box_placement_fn = uniform_placement\n",
    "    ramp_placement_fn = uniform_placement\n",
    "    agent_placement_fn = uniform_placement\n",
    "\n",
    "    env.add_module(Agents(n_agents,\n",
    "                          placement_fn=agent_placement_fn,\n",
    "                          color=[np.array((66., 235., 244., 255.)) / 255] * n_agents,\n",
    "                          friction=other_friction,\n",
    "                          polar_obs=polar_obs))\n",
    "\n",
    "    if np.max(n_boxes) > 0:\n",
    "        env.add_module(Boxes(n_boxes=n_boxes, placement_fn=box_placement_fn,\n",
    "                             friction=box_floor_friction, polar_obs=polar_obs,\n",
    "                             n_elongated_boxes=0,\n",
    "                             boxid_obs=boxid_obs,\n",
    "                             box_only_z_rot=box_only_z_rot,\n",
    "                             boxsize_obs=boxsize_obs,\n",
    "                             free=True))\n",
    "\n",
    "    if n_ramps > 0:\n",
    "        env.add_module(Ramps(n_ramps=n_ramps, placement_fn=ramp_placement_fn,\n",
    "                             friction=other_friction, polar_obs=polar_obs,\n",
    "                             pad_ramp_size=pad_ramp_size, free=True))\n",
    "\n",
    "    # if n_lidar_per_agent > 0 and visualize_lidar:\n",
    "    #     env.add_module(LidarSites(n_agents=n_agents, n_lidar_per_agent=n_lidar_per_agent))\n",
    "\n",
    "    # env.add_module(WorldConstants(gravity=gravity))\n",
    "\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env()\n",
    "env.gen_sys(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def randomise_action(act, random_key):\n",
    "    random_key, _ = random.split(random_key)\n",
    "    return random.uniform(random_key, shape=act.shape, minval=-0.25, maxval=0.25), random_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the inital environment states\n",
    "act_size = env.sys.act_size()\n",
    "\n",
    "jit_step_fn = jax.jit(env.step)\n",
    "jit_batch_reset_fn = jax.jit(jax.vmap(env.reset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def play_step_fn(state: State, act: Action, random_key: RNGKey):\n",
    "    act, random_key = randomise_action(act, random_key)\n",
    "    state = jit_step_fn(state, act)\n",
    "    return state, act, random_key, state.pipeline_state\n",
    "\n",
    "@partial(jax.jit, static_argnames=(\"play_step_fn\", \"episode_length\"))\n",
    "def generate_unroll(\n",
    "    init_state: State,\n",
    "    act: Action,\n",
    "    random_key: RNGKey,\n",
    "    episode_length: int,\n",
    "    play_step_fn) -> Tuple[State, Action, RNGKey]:\n",
    "    \"\"\"Generates an episode according to random action, returns the final state of\n",
    "    the episode and the transitions of the episode.\n",
    "\n",
    "    Args:\n",
    "        init_state: first state of the rollout.\n",
    "        act: The initial action\n",
    "        random_key: random key for stochasiticity handling.\n",
    "        episode_length: length of the rollout.\n",
    "        index: index of the rollout.\n",
    "        play_step_fn: function describing how a step need to be taken.\n",
    "\n",
    "    Returns:\n",
    "        A new state, the experienced transition.\n",
    "    \"\"\"\n",
    "    @jax.jit\n",
    "    def scan_play_step_fn(\n",
    "        carry: Tuple[State, Action, RNGKey], unused_arg: Any) ->Tuple[Tuple[State, Action, RNGKey], PipelineState]:\n",
    "        state, act, random_key, p_states = play_step_fn(*carry)\n",
    "        return (state, act, random_key), p_states\n",
    "\n",
    "\n",
    "    (dst_state, dst_act, key), rollout = jax.lax.scan(\n",
    "        scan_play_step_fn, (init_state, act, random_key), None, length=episode_length)\n",
    "\n",
    "    return dst_state, rollout\n",
    "\n",
    "unroll_fn = partial(\n",
    "    generate_unroll,\n",
    "    episode_length=episode_length,\n",
    "    play_step_fn=play_step_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rollout time for batch size 2 : 26.836660146713257\n",
      "Rollout time for batch size 4 : 23.991141080856323\n",
      "Rollout time for batch size 8 : 23.871275901794434\n",
      "Rollout time for batch size 16 : 23.65753674507141\n",
      "Rollout time for batch size 32 : 23.599459171295166\n",
      "Rollout time for batch size 64 : 25.184409856796265\n",
      "Rollout time for batch size 128 : 36.60212469100952\n",
      "Rollout time for batch size 256 : 57.67041349411011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:13:13.041596: W external/xla/xla/service/hlo_rematerialization.cc:2209] Can't reduce memory use below 17.73GiB (19041386496 bytes) by rematerialization; only reduced to 21.05GiB (22606288036 bytes)\n",
      "2023-06-16 17:13:33.044087: W external/tsl/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.00GiB (rounded to 8594884608)requested by op \n",
      "2023-06-16 17:13:33.044609: W external/tsl/tsl/framework/bfc_allocator.cc:497] **************************************************************************************______________\n",
      "2023-06-16 17:13:33.045664: E external/xla/xla/pjrt/pjrt_stream_executor_client.cc:2469] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 8594884472 bytes.\n",
      "BufferAssignment OOM Debugging.\n",
      "BufferAssignment stats:\n",
      "             parameter allocation:   10.62MiB\n",
      "              constant allocation:     8.8KiB\n",
      "        maybe_live_out allocation:    9.98GiB\n",
      "     preallocated temp allocation:    8.00GiB\n",
      "                 total allocation:   18.00GiB\n",
      "Peak buffers:\n",
      "\tBuffer 1:\n",
      "\t\tSize: 6.04GiB\n",
      "\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/broadcast_in_dim[shape=(1000, 512, 132, 24) broadcast_dimensions=()]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n",
      "\t\tXLA Label: broadcast\n",
      "\t\tShape: f32[1000,512,132,24]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 2:\n",
      "\t\tSize: 6.04GiB\n",
      "\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n",
      "\t\tXLA Label: transpose\n",
      "\t\tShape: f32[512,1000,132,24]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 3:\n",
      "\t\tSize: 1.10GiB\n",
      "\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/broadcast_in_dim[shape=(1000, 512, 24, 24) broadcast_dimensions=()]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n",
      "\t\tXLA Label: broadcast\n",
      "\t\tShape: f32[1000,512,24,24]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 4:\n",
      "\t\tSize: 1.10GiB\n",
      "\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n",
      "\t\tXLA Label: transpose\n",
      "\t\tShape: f32[512,1000,24,24]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 5:\n",
      "\t\tSize: 1.10GiB\n",
      "\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[512,1000,24,24]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 6:\n",
      "\t\tSize: 257.81MiB\n",
      "\t\tXLA Label: copy\n",
      "\t\tShape: f32[1000,512,132]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 7:\n",
      "\t\tSize: 257.81MiB\n",
      "\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n",
      "\t\tXLA Label: transpose\n",
      "\t\tShape: f32[512,1000,132]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 8:\n",
      "\t\tSize: 257.81MiB\n",
      "\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n",
      "\t\tXLA Label: transpose\n",
      "\t\tShape: f32[512,1000,132]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 9:\n",
      "\t\tSize: 140.62MiB\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[1000,512,24,3]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 10:\n",
      "\t\tSize: 140.62MiB\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[1000,512,24,3]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 11:\n",
      "\t\tSize: 140.62MiB\n",
      "\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n",
      "\t\tXLA Label: transpose\n",
      "\t\tShape: f32[512,1000,24,3]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 12:\n",
      "\t\tSize: 140.62MiB\n",
      "\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n",
      "\t\tXLA Label: transpose\n",
      "\t\tShape: f32[512,1000,24,3]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 13:\n",
      "\t\tSize: 140.62MiB\n",
      "\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n",
      "\t\tXLA Label: transpose\n",
      "\t\tShape: f32[512,1000,24,3]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 14:\n",
      "\t\tSize: 140.62MiB\n",
      "\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n",
      "\t\tXLA Label: transpose\n",
      "\t\tShape: f32[512,1000,24,3]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 15:\n",
      "\t\tSize: 105.47MiB\n",
      "\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/broadcast_in_dim[shape=(1000, 512, 6, 3, 3) broadcast_dimensions=()]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n",
      "\t\tXLA Label: broadcast\n",
      "\t\tShape: f32[1000,512,6,3,3]\n",
      "\t\t==========================\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 8594884472 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:   10.62MiB\n              constant allocation:     8.8KiB\n        maybe_live_out allocation:    9.98GiB\n     preallocated temp allocation:    8.00GiB\n                 total allocation:   18.00GiB\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 6.04GiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/broadcast_in_dim[shape=(1000, 512, 132, 24) broadcast_dimensions=()]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: broadcast\n\t\tShape: f32[1000,512,132,24]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 6.04GiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,132,24]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 1.10GiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/broadcast_in_dim[shape=(1000, 512, 24, 24) broadcast_dimensions=()]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: broadcast\n\t\tShape: f32[1000,512,24,24]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 1.10GiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,24,24]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 1.10GiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: fusion\n\t\tShape: f32[512,1000,24,24]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 257.81MiB\n\t\tXLA Label: copy\n\t\tShape: f32[1000,512,132]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 257.81MiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,132]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 257.81MiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,132]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 140.62MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[1000,512,24,3]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 140.62MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[1000,512,24,3]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 140.62MiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,24,3]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 140.62MiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,24,3]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 140.62MiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,24,3]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 140.62MiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,24,3]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 105.47MiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/broadcast_in_dim[shape=(1000, 512, 6, 3, 3) broadcast_dimensions=()]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: broadcast\n\t\tShape: f32[1000,512,6,3,3]\n\t\t==========================\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m acts \u001b[38;5;241m=\u001b[39m jp\u001b[38;5;241m.\u001b[39mzeros(shape\u001b[38;5;241m=\u001b[39m(batch_size, env\u001b[38;5;241m.\u001b[39msys\u001b[38;5;241m.\u001b[39mact_size()), dtype\u001b[38;5;241m=\u001b[39mjp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     14\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 15\u001b[0m dst_states, rollouts \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_rollout_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m et \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     17\u001b[0m dt \u001b[38;5;241m=\u001b[39m et \u001b[38;5;241m-\u001b[39m start_time\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/maax/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:1346\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1341\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_token_bufs(\n\u001b[1;32m   1342\u001b[0m       results\u001b[38;5;241m.\u001b[39mdisassemble_prefix_into_single_device_arrays(\n\u001b[1;32m   1343\u001b[0m           \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordered_effects)),\n\u001b[1;32m   1344\u001b[0m       results\u001b[38;5;241m.\u001b[39mconsume_token())\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1346\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxla_executable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sharded\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_bufs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mneeds_check_special():\n\u001b[1;32m   1348\u001b[0m   out_arrays \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mdisassemble_into_single_device_arrays()\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 8594884472 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:   10.62MiB\n              constant allocation:     8.8KiB\n        maybe_live_out allocation:    9.98GiB\n     preallocated temp allocation:    8.00GiB\n                 total allocation:   18.00GiB\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 6.04GiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/broadcast_in_dim[shape=(1000, 512, 132, 24) broadcast_dimensions=()]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: broadcast\n\t\tShape: f32[1000,512,132,24]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 6.04GiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,132,24]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 1.10GiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/broadcast_in_dim[shape=(1000, 512, 24, 24) broadcast_dimensions=()]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: broadcast\n\t\tShape: f32[1000,512,24,24]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 1.10GiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,24,24]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 1.10GiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: fusion\n\t\tShape: f32[512,1000,24,24]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 257.81MiB\n\t\tXLA Label: copy\n\t\tShape: f32[1000,512,132]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 257.81MiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,132]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 257.81MiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,132]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 140.62MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[1000,512,24,3]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 140.62MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[1000,512,24,3]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 140.62MiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,24,3]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 140.62MiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,24,3]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 140.62MiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,24,3]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 140.62MiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/while[cond_nconsts=0 body_nconsts=0]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: transpose\n\t\tShape: f32[512,1000,24,3]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 105.47MiB\n\t\tOperator: op_name=\"jit(<unnamed function>)/jit(main)/vmap(jit(generate_unroll))/broadcast_in_dim[shape=(1000, 512, 6, 3, 3) broadcast_dimensions=()]\" source_file=\"/var/tmp/pbs.7759721.pbs/ipykernel_3851952/2081353713.py\" source_line=35\n\t\tXLA Label: broadcast\n\t\tShape: f32[1000,512,6,3,3]\n\t\t==========================\n\n"
     ]
    }
   ],
   "source": [
    "# # Run rollouts and time them\n",
    "batch_rollout_fn = jax.jit(jax.vmap(unroll_fn))\n",
    "batch_time = dict()\n",
    "iterations = 6\n",
    "\n",
    "# Perform rollout for each batch size\n",
    "for i in range(iterations):\n",
    "    for batch_size in batch_sizes:\n",
    "        random_key, subkey = jax.random.split(random_key)\n",
    "        keys = jax.random.split(subkey, num=batch_size)\n",
    "        # Define initial batches states and actions\n",
    "        init_states = jit_batch_reset_fn(keys)\n",
    "        acts = jp.zeros(shape=(batch_size, env.sys.act_size()), dtype=jp.float32)\n",
    "        start_time = time.time()\n",
    "        dst_states, rollouts = batch_rollout_fn(init_states, acts, keys)\n",
    "        et = time.time()\n",
    "        dt = et - start_time\n",
    "        print(f\"Rollout time for batch size {batch_size} : {dt}\")\n",
    "        if batch_size in batch_time:\n",
    "            batch_time[batch_size].append(dt)\n",
    "        else:\n",
    "            batch_time[batch_size] = [dt]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 128\n",
    "# random_key, subkey = jax.random.split(random_key)\n",
    "# keys = jax.random.split(subkey, num=batch_size)\n",
    "# # Define initial batches states and actions\n",
    "# init_states = jit_batch_reset_fn(keys)\n",
    "# acts = jp.zeros(shape=(batch_size, env.sys.act_size()), dtype=jp.float32)\n",
    "# start_time = time.time()\n",
    "# dst_states, rollouts = batch_rollout_fn(init_states, acts, keys)\n",
    "# et = time.time()\n",
    "# dt = et - start_time\n",
    "# print(f\"Rollout time for batch size {batch_size} : {dt}\")\n",
    "# batch_time[batch_size] = dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save batch times\n",
    "with open('batch_times_no_walls_2{}.json'.format(episode_length), 'w') as f: \n",
    "    json.dump(batch_time, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('maax_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d286b5a782650f2d9ae8fe3e234d77a318fcb8a23bb1ca21ad01d6849611a0dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
