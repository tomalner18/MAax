{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('/Users/tom/dev/imperial/FYP/MAax/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldgen import Floor, WorldBuilder, WorldParams\n",
    "from mae_envs.modules.agents import Agents\n",
    "from mae_envs.modules.walls import RandomWalls, WallScenarios\n",
    "from mae_envs.modules.world import FloorAttributes, WorldConstants\n",
    "from mae_envs.modules.objects import Boxes, Cylinders, LidarSites, Ramps\n",
    "from mae_envs.modules.util import uniform_placement, center_placement, close_to_other_object_placement\n",
    "from mae_envs.envs.hide_and_seek import quadrant_placement, outside_quadrant_placement, HideAndSeekRewardWrapper, TrackStatWrapper\n",
    "from maax.envs.base import Base\n",
    "from mae_envs.wrappers.multi_agent import (SplitMultiAgentActions,\n",
    "                                           SplitObservations, SelectKeysWrapper)\n",
    "from mae_envs.wrappers.util import (ConcatenateObsWrapper,\n",
    "                                    MaskActionWrapper, SpoofEntityWrapper,\n",
    "                                    AddConstantObservationsWrapper, MWrapper)\n",
    "from mae_envs.wrappers.manipulation import (LockObjWrapper, LockAllWrapper)\n",
    "from mae_envs.wrappers.lidar import Lidar\n",
    "from mae_envs.wrappers.line_of_sight import (AgentAgentObsMask2D, AgentAgentContactMask2D,\n",
    "                                            AgentGeomObsMask2D, AgentSiteObsMask2D)\n",
    "from mae_envs.wrappers.prep_phase import (PreparationPhase, NoActionsInPrepPhase,\n",
    "                                          MaskPrepPhaseAction)\n",
    "from mae_envs.wrappers.limit_mvmnt import RestrictAgentsRect\n",
    "from mae_envs.wrappers.team import TeamMembership\n",
    "from mae_envs.wrappers.food import FoodHealthWrapper, AlwaysEatWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brax\n",
    "import numpy as np\n",
    "from brax.io import mjcf, html\n",
    "from maax.envs.base import Base\n",
    "from mae_envs.util.types import RNGKey, PipelineState, Action\n",
    "from brax.generalized import pipeline\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "\n",
    "from jax import random\n",
    "\n",
    "from IPython.display import HTML, clear_output\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maax.envs.base import State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 34\n",
    "horizon = 100\n",
    "n_frames = 1\n",
    "random_key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(deterministic_mode=False,\n",
    "             floor_size=6.0, grid_size=30, door_size=2,\n",
    "             n_hiders=2, n_seekers=2, max_n_agents=None,\n",
    "             n_boxes=2, n_ramps=1, n_elongated_boxes=0,\n",
    "             rand_num_elongated_boxes=False, n_min_boxes=None,\n",
    "             box_size=0.5, boxid_obs=False, box_only_z_rot=True,\n",
    "             rew_type='joint_zero_sum',\n",
    "             lock_box=True, grab_box=True, lock_ramp=True,\n",
    "             lock_type='any_lock_specific',\n",
    "             lock_grab_radius=0.25, lock_out_of_vision=True, grab_exclusive=False,\n",
    "             grab_out_of_vision=False, grab_selective=False,\n",
    "             box_floor_friction=0.2, other_friction=0.01, gravity=[0, 0, -50],\n",
    "             action_lims=(-0.9, 0.9), polar_obs=True,\n",
    "             scenario='quadrant', quadrant_game_hider_uniform_placement=False,\n",
    "             p_door_dropout=0.0,\n",
    "             n_rooms=4, random_room_number=True, prob_outside_walls=1.0,\n",
    "             n_lidar_per_agent=0, visualize_lidar=False, compress_lidar_scale=None,\n",
    "             hiders_together_radius=None, seekers_together_radius=None,\n",
    "             prep_fraction=0.4, prep_obs=False,\n",
    "             team_size_obs=False,\n",
    "             restrict_rect=None, penalize_objects_out=False,\n",
    "             n_food=0, food_radius=None, food_respawn_time=None, max_food_health=1,\n",
    "             food_together_radius=None, food_rew_type='selfish', eat_when_caught=False,\n",
    "             food_reward_scale=1.0, food_normal_centered=False, food_box_centered=False,\n",
    "             n_food_cluster=1):\n",
    "\n",
    "    grab_radius_multiplier = lock_grab_radius / box_size\n",
    "    lock_radius_multiplier = lock_grab_radius / box_size\n",
    "\n",
    "    env = Base(n_agents=n_hiders + n_seekers, n_frames=n_frames, horizon=horizon,\n",
    "               floor_size=floor_size, grid_size=grid_size,\n",
    "               action_lims=action_lims,\n",
    "               deterministic_mode=deterministic_mode)\n",
    "\n",
    "    if scenario == 'randomwalls':\n",
    "        env.add_module(RandomWalls(\n",
    "            grid_size=grid_size, num_rooms=n_rooms,\n",
    "            random_room_number=random_room_number, min_room_size=6,\n",
    "            door_size=door_size,\n",
    "            prob_outside_walls=prob_outside_walls, gen_door_obs=False))\n",
    "        box_placement_fn = uniform_placement\n",
    "        ramp_placement_fn = uniform_placement\n",
    "        cell_size = floor_size / grid_size\n",
    "\n",
    "        first_hider_placement = uniform_placement\n",
    "        if hiders_together_radius is not None:\n",
    "            htr_in_cells = np.ceil(hiders_together_radius / cell_size).astype(int)\n",
    "\n",
    "            env.metadata['hiders_together_radius'] = htr_in_cells\n",
    "\n",
    "            close_to_first_hider_placement = close_to_other_object_placement(\n",
    "                                                \"agent\", 0, \"hiders_together_radius\")\n",
    "\n",
    "            agent_placement_fn = [first_hider_placement] + \\\n",
    "                                 [close_to_first_hider_placement] * (n_hiders - 1)\n",
    "        else:\n",
    "            agent_placement_fn = [first_hider_placement] * n_hiders\n",
    "\n",
    "        first_seeker_placement = uniform_placement\n",
    "\n",
    "        if seekers_together_radius is not None:\n",
    "            str_in_cells = np.ceil(seekers_together_radius / cell_size).astype(int)\n",
    "\n",
    "            env.metadata['seekers_together_radius'] = str_in_cells\n",
    "\n",
    "            close_to_first_seeker_placement = close_to_other_object_placement(\n",
    "                                                \"agent\", n_hiders, \"seekers_together_radius\")\n",
    "\n",
    "            agent_placement_fn += [first_seeker_placement] + \\\n",
    "                                  [close_to_first_seeker_placement] * (n_seekers - 1)\n",
    "        else:\n",
    "            agent_placement_fn += [first_seeker_placement] * (n_seekers)\n",
    "\n",
    "    elif scenario == 'quadrant':\n",
    "        env.add_module(WallScenarios(grid_size=grid_size, door_size=door_size,\n",
    "                                     scenario=scenario, friction=other_friction,\n",
    "                                     p_door_dropout=p_door_dropout))\n",
    "        box_placement_fn = quadrant_placement\n",
    "        ramp_placement_fn = uniform_placement\n",
    "        hider_placement = uniform_placement if quadrant_game_hider_uniform_placement else quadrant_placement\n",
    "        agent_placement_fn = [hider_placement] * n_hiders + [outside_quadrant_placement] * n_seekers\n",
    "    else:\n",
    "        raise ValueError(f\"Scenario {scenario} not supported.\")\n",
    "\n",
    "    env.add_module(Agents(n_hiders + n_seekers,\n",
    "                          placement_fn=agent_placement_fn,\n",
    "                          color=[np.array((66., 235., 244., 255.)) / 255] * n_hiders + [np.array((240., 20., 50., 255.)) / 255] * n_seekers,\n",
    "                          friction=other_friction,\n",
    "                          polar_obs=polar_obs))\n",
    "    if np.max(n_boxes) > 0:\n",
    "        env.add_module(Boxes(n_boxes=n_boxes, placement_fn=box_placement_fn,\n",
    "                             friction=box_floor_friction, polar_obs=polar_obs,\n",
    "                             n_elongated_boxes=n_elongated_boxes,\n",
    "                             boxid_obs=boxid_obs, box_only_z_rot=box_only_z_rot))\n",
    "    if n_ramps > 0:\n",
    "        env.add_module(Ramps(n_ramps=n_ramps, placement_fn=ramp_placement_fn, friction=other_friction, polar_obs=polar_obs,\n",
    "                             pad_ramp_size=(np.max(n_elongated_boxes) > 0)))\n",
    "\n",
    "    # if box_floor_friction is not None:\n",
    "    #     env.add_module(FloorAttributes(friction=box_floor_friction))\n",
    "\n",
    "    keys_self = ['agent_qpos_qvel', 'hider', 'prep_obs']\n",
    "    keys_mask_self = ['mask_aa_con']\n",
    "    keys_external = ['agent_qpos_qvel']\n",
    "    keys_copy = ['you_lock', 'team_lock', 'ramp_you_lock', 'ramp_team_lock']\n",
    "    keys_mask_external = []\n",
    "    # env = SplitMultiAgentActions(env)\n",
    "    if team_size_obs:\n",
    "        keys_self += ['team_size']\n",
    "    env = TeamMembership(env, np.append(np.zeros((n_hiders,)), np.ones((n_seekers,))))\n",
    "    # env = AgentAgentObsMask2D(env)\n",
    "    env = AgentAgentContactMask2D(env)\n",
    "    hider_obs = np.array([[1]] * n_hiders + [[0]] * n_seekers)\n",
    "    env = AddConstantObservationsWrapper(env, new_obs={'hider': hider_obs})\n",
    "    env = HideAndSeekRewardWrapper(env, n_hiders=n_hiders, n_seekers=n_seekers,\n",
    "                                   rew_type=rew_type)\n",
    "\n",
    "    env = PreparationPhase(env, prep_fraction=prep_fraction)\n",
    "\n",
    "    if np.max(n_boxes) > 0:\n",
    "        # env = AgentGeomObsMask2D(env, pos_obs_key='box_pos', mask_obs_key='mask_ab_obs',\n",
    "        #                          geom_idxs_obs_key='box_geom_idxs')\n",
    "        keys_external += ['box_obs']\n",
    "\n",
    "    # if lock_box and np.max(n_boxes) > 0:\n",
    "    #     env = LockObjWrapper(env, body_names=[f'moveable_box{i}' for i in range(np.max(n_boxes))],\n",
    "    #                          agent_idx_allowed_to_lock=np.arange(n_hiders+n_seekers),\n",
    "    #                          lock_type=lock_type, radius_multiplier=lock_radius_multiplier,\n",
    "    #                          obj_in_game_metadata_keys=[\"curr_n_boxes\"],\n",
    "    #                          agent_allowed_to_lock_keys=None if lock_out_of_vision else [\"mask_ab_obs\"])\n",
    "\n",
    "    if n_ramps > 0:\n",
    "        # if lock_ramp:\n",
    "        #     env = LockObjWrapper(env, body_names=[f'ramp{i}:ramp' for i in range(n_ramps)],\n",
    "        #                          agent_idx_allowed_to_lock=np.arange(n_hiders+n_seekers),\n",
    "        #                          lock_type=lock_type, ac_obs_prefix='ramp_',\n",
    "        #                          radius_multiplier=lock_radius_multiplier,\n",
    "        #                          obj_in_game_metadata_keys=['curr_n_ramps'],\n",
    "        #                          agent_allowed_to_lock_keys=None if lock_out_of_vision else [\"mask_ar_obs\"])\n",
    "        keys_external += ['ramp_obs']\n",
    "\n",
    "\n",
    "    if prep_obs:\n",
    "        env = TrackStatWrapper(env, np.max(n_boxes), n_ramps, n_food)\n",
    "    env = SplitObservations(env, keys_self + keys_mask_self, keys_copy=keys_copy, keys_self_matrices=keys_mask_self)\n",
    "    # env = SpoofEntityWrapper(env, np.max(n_boxes), ['box_obs', 'you_lock', 'team_lock', 'obj_lock'], ['mask_ab_obs'])\n",
    "\n",
    "    # if max_n_agents is not None:\n",
    "    #     env = SpoofEntityWrapper(env, max_n_agents, ['agent_qpos_qvel', 'hider', 'prep_obs'], ['mask_aa_obs'])\n",
    "    # env = LockAllWrapper(env, remove_object_specific_lock=True)\n",
    "    env = NoActionsInPrepPhase(env, np.arange(n_hiders, n_hiders + n_seekers))\n",
    "    # env = ConcatenateObsWrapper(env, {'agent_qpos_qvel': ['agent_qpos_qvel'],\n",
    "    #                                   'box_obs': ['box_obs'],\n",
    "    #                                   'ramp_obs': ['ramp_obs']})\n",
    "    env = SelectKeysWrapper(env, keys_self=keys_self,\n",
    "                            keys_other=keys_external + keys_mask_self + keys_mask_external)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = make_env(random_key)\n",
    "\n",
    "test_env.gen_sys(seed)\n",
    "\n",
    "state = jax.jit(test_env.reset)(random_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomise_action(act, random_key):\n",
    "    random_key, sub_key = random.split(random_key)\n",
    "    return random.uniform(random_key, shape=act.shape, minval=-0.25, maxval=0.25), random_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_step_fn = jax.jit(test_env.step)\n",
    "act_size = test_env.sys.act_size()\n",
    "\n",
    "act = jp.zeros(shape=(test_env.n_agents, act_size // test_env.n_agents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [-1. -1.  1.  1.]\n",
      "Outgoing prep reward: [-1. -1.  1.  1.]\n",
      "Reward: [-1. -1.  1.  1.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n",
      "Reward: [0. 0. 0. 0.]\n",
      "Hide and seek reward\n",
      "Incoming prep reward: [-1. -1.  1.  1.]\n",
      "Reward before: [-1. -1.  1.  1.]\n",
      "Reward after: [0. 0. 0. 0.]\n",
      "Outgoing prep reward: [0. 0. 0. 0.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     rollout\u001b[39m.\u001b[39mappend(state\u001b[39m.\u001b[39mpipeline_state)\n\u001b[1;32m      6\u001b[0m     \u001b[39m# state = test_env.step(state, act)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     state \u001b[39m=\u001b[39m jit_step_fn(state, act)\n\u001b[1;32m      8\u001b[0m     jax\u001b[39m.\u001b[39mdebug\u001b[39m.\u001b[39mprint(\u001b[39m'\u001b[39m\u001b[39mReward: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m, state\u001b[39m.\u001b[39mreward)\n\u001b[1;32m     10\u001b[0m html\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39magents.html\u001b[39m\u001b[39m'\u001b[39m, test_env\u001b[39m.\u001b[39msys, rollout)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/maax_venv/lib/python3.10/site-packages/jax/_src/pjit.py:238\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39m@api_boundary\u001b[39m\n\u001b[1;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcache_miss\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 238\u001b[0m   outs, out_flat, out_tree, args_flat \u001b[39m=\u001b[39m _python_pjit_helper(\n\u001b[1;32m    239\u001b[0m       fun, infer_params_fn, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    241\u001b[0m   executable \u001b[39m=\u001b[39m _read_most_recent_pjit_call_executable()\n\u001b[1;32m    243\u001b[0m   use_fastpath \u001b[39m=\u001b[39m (\n\u001b[1;32m    244\u001b[0m       executable \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    245\u001b[0m       \u001b[39misinstance\u001b[39m(executable, pxla\u001b[39m.\u001b[39mMeshExecutable) \u001b[39mand\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    251\u001b[0m       \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(x, xc\u001b[39m.\u001b[39mArrayImpl) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m out_flat)\n\u001b[1;32m    252\u001b[0m   )\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/maax_venv/lib/python3.10/site-packages/jax/_src/pjit.py:185\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, infer_params_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m   dispatch\u001b[39m.\u001b[39mcheck_arg(arg)\n\u001b[1;32m    184\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m   out_flat \u001b[39m=\u001b[39m pjit_p\u001b[39m.\u001b[39;49mbind(\u001b[39m*\u001b[39;49margs_flat, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    186\u001b[0m \u001b[39mexcept\u001b[39;00m pxla\u001b[39m.\u001b[39mDeviceAssignmentMismatchError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    187\u001b[0m   fails, \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39margs\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/maax_venv/lib/python3.10/site-packages/jax/_src/core.py:2592\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2588\u001b[0m axis_main \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m((axis_frame(a)\u001b[39m.\u001b[39mmain_trace \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m used_axis_names(\u001b[39mself\u001b[39m, params)),\n\u001b[1;32m   2589\u001b[0m                 default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m t: \u001b[39mgetattr\u001b[39m(t, \u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m   2590\u001b[0m top_trace \u001b[39m=\u001b[39m (top_trace \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m axis_main \u001b[39mor\u001b[39;00m axis_main\u001b[39m.\u001b[39mlevel \u001b[39m<\u001b[39m top_trace\u001b[39m.\u001b[39mlevel\n\u001b[1;32m   2591\u001b[0m              \u001b[39melse\u001b[39;00m axis_main\u001b[39m.\u001b[39mwith_cur_sublevel())\n\u001b[0;32m-> 2592\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbind_with_trace(top_trace, args, params)\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/maax_venv/lib/python3.10/site-packages/jax/_src/core.py:363\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 363\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39;49mprocess_primitive(\u001b[39mself\u001b[39;49m, \u001b[39mmap\u001b[39;49m(trace\u001b[39m.\u001b[39;49mfull_raise, args), params)\n\u001b[1;32m    364\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/maax_venv/lib/python3.10/site-packages/jax/_src/core.py:817\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_primitive\u001b[39m(\u001b[39mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 817\u001b[0m   \u001b[39mreturn\u001b[39;00m primitive\u001b[39m.\u001b[39;49mimpl(\u001b[39m*\u001b[39;49mtracers, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/maax_venv/lib/python3.10/site-packages/jax/_src/pjit.py:1252\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1246\u001b[0m   distributed_debug_log((\u001b[39m\"\u001b[39m\u001b[39mRunning pjit\u001b[39m\u001b[39m'\u001b[39m\u001b[39md function\u001b[39m\u001b[39m\"\u001b[39m, name),\n\u001b[1;32m   1247\u001b[0m                         (\u001b[39m\"\u001b[39m\u001b[39min_shardings\u001b[39m\u001b[39m\"\u001b[39m, in_shardings),\n\u001b[1;32m   1248\u001b[0m                         (\u001b[39m\"\u001b[39m\u001b[39mout_shardings\u001b[39m\u001b[39m\"\u001b[39m, out_shardings),\n\u001b[1;32m   1249\u001b[0m                         (\u001b[39m\"\u001b[39m\u001b[39mabstract args\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mmap\u001b[39m(xla\u001b[39m.\u001b[39mabstractify, args)),\n\u001b[1;32m   1250\u001b[0m                         (\u001b[39m\"\u001b[39m\u001b[39mfingerprint\u001b[39m\u001b[39m\"\u001b[39m, fingerprint))\n\u001b[1;32m   1251\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1252\u001b[0m   \u001b[39mreturn\u001b[39;00m compiled\u001b[39m.\u001b[39;49munsafe_call(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   1253\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m   \u001b[39massert\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_nans \u001b[39mor\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_infs  \u001b[39m# compiled_fun can only raise in this case\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/maax_venv/lib/python3.10/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m   \u001b[39mwith\u001b[39;00m TraceAnnotation(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    315\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/maax_venv/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:1908\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1905\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mordered_effects \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_unordered_effects\n\u001b[1;32m   1906\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_host_callbacks):\n\u001b[1;32m   1907\u001b[0m   input_bufs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_tokens_to_inputs(input_bufs)\n\u001b[0;32m-> 1908\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mxla_executable\u001b[39m.\u001b[39;49mexecute_sharded(\n\u001b[1;32m   1909\u001b[0m       input_bufs, with_tokens\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m   1910\u001b[0m   )\n\u001b[1;32m   1911\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_token_bufs(\n\u001b[1;32m   1912\u001b[0m       results\u001b[39m.\u001b[39mdisassemble_prefix_into_single_device_arrays(\n\u001b[1;32m   1913\u001b[0m           \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mordered_effects)),\n\u001b[1;32m   1914\u001b[0m       results\u001b[39m.\u001b[39mconsume_token())\n\u001b[1;32m   1915\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rollout = []\n",
    "\n",
    "for i in range(horizon):\n",
    "    act, random_key = jax.lax.cond(i % 50 == 0, randomise_action, lambda x, y: (x, y), act, random_key)\n",
    "    rollout.append(state.pipeline_state)\n",
    "    # state = test_env.step(state, act)\n",
    "    state = jit_step_fn(state, act)\n",
    "    jax.debug.print('Reward: {}', state.reward)\n",
    "\n",
    "html.save('agents.html', test_env.sys, rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "# def play_step_fn(state: State, act: Action, random_key: RNGKey, index: int):\n",
    "#     act, random_key = jax.lax.cond(index % 50 == 0, randomise_action, lambda x, y: (x, y), act, random_key)\n",
    "#     state = jit_step_fn(state, act)\n",
    "#     return state, act, random_key, index + 1, state.pipeline_state\n",
    "\n",
    "# def scan_play_step_fn(\n",
    "#     carry: Tuple[State, Action, RNGKey, int], unused_arg: Any\n",
    "# ) ->Tuple[Tuple[State, RNGKey, int], PipelineState]:\n",
    "#     state, act, random_key, index, p_states = play_step_fn(*carry)\n",
    "#     return (state, act, random_key, index), p_states\n",
    "    \n",
    "\n",
    "# (dst_state, dst_act, key, index), rollout = jax.lax.scan(scan_play_step_fn, (state, act, random_key, 0), None, length=horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states_list = []\n",
    "# print(dst_state.info)\n",
    "# print(dst_state.reward)\n",
    "\n",
    "# for i in range(horizon):\n",
    "#     s = jax.tree_util.tree_map(lambda x: x[i], rollout)\n",
    "#     states_list.append(s)\n",
    "\n",
    "\n",
    "# html.save('agents.html', test_env.sys, states_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('maax_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d286b5a782650f2d9ae8fe3e234d77a318fcb8a23bb1ca21ad01d6849611a0dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
