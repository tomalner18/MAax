{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('/Users/tom/dev/imperial/FYP/MAax/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldgen import Floor, WorldBuilder, WorldParams\n",
    "from mae_envs.modules.agents import Agents\n",
    "from mae_envs.modules.walls import RandomWalls, WallScenarios\n",
    "from mae_envs.modules.world import FloorAttributes, WorldConstants\n",
    "from mae_envs.modules.objects import Boxes, Cylinders, LidarSites, Ramps\n",
    "from mae_envs.modules.util import uniform_placement, centre_placement, proximity_placement\n",
    "from mae_envs.envs.hide_and_seek import quad_placement, outside_quad_placement, HideAndSeekRewardWrapper, TrackStatWrapper\n",
    "from maax.envs.base import Base\n",
    "from mae_envs.wrappers.multi_agent import (SplitMultiAgentActions,\n",
    "                                           SplitObservations, SelectKeysWrapper)\n",
    "from mae_envs.wrappers.util import (ConcatenateObsWrapper,\n",
    "                                    MaskActionWrapper, SpoofEntityWrapper,\n",
    "                                    AddConstantObservationsWrapper, FlattenDictObsWrapper, MWrapper)\n",
    "from mae_envs.wrappers.manipulation import (LockObjWrapper, LockAllWrapper)\n",
    "from mae_envs.wrappers.lidar import Lidar\n",
    "from mae_envs.wrappers.line_of_sight import (AgentAgentObsMask2D, AgentAgentContactMask2D,\n",
    "                                            AgentGeomObsMask2D, AgentSiteObsMask2D)\n",
    "from mae_envs.wrappers.prep_phase import (PreparationPhase, NoActionsInPrepPhase,\n",
    "                                          MaskPrepPhaseAction)\n",
    "from mae_envs.wrappers.limit_mvmnt import RestrictAgentsRect\n",
    "from mae_envs.wrappers.team import TeamMembership\n",
    "from mae_envs.wrappers.food import FoodHealthWrapper, AlwaysEatWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brax\n",
    "import numpy as np\n",
    "from brax.io import mjcf, html\n",
    "from maax.envs.base import Base\n",
    "from mae_envs.util.types import RNGKey, PipelineState, Action\n",
    "from brax.generalized import pipeline\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "\n",
    "from jax import random\n",
    "\n",
    "from IPython.display import HTML, clear_output\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maax.envs.base import State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 34\n",
    "horizon = 100\n",
    "n_frames = 1\n",
    "random_key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(deterministic_mode=False,\n",
    "             floor_size=6.0, grid_size=30, door_size=2,\n",
    "             n_hiders=2, n_seekers=2, max_n_agents=None,\n",
    "             n_boxes=2, n_ramps=1, n_elongated_boxes=0,\n",
    "             rand_num_elongated_boxes=False, n_min_boxes=None,\n",
    "             box_size=0.5, boxid_obs=False, box_only_z_rot=True,\n",
    "             rew_type='joint_zero_sum',\n",
    "             lock_box=True, grab_box=True, lock_ramp=True,\n",
    "             lock_type='any_lock_specific',\n",
    "             lock_grab_radius=0.25, lock_out_of_vision=True, grab_exclusive=False,\n",
    "             grab_out_of_vision=False, grab_selective=False,\n",
    "             box_floor_friction=0.2, other_friction=0.01, gravity=[0, 0, -50],\n",
    "             action_lims=(-0.9, 0.9), polar_obs=True,\n",
    "             scenario='quad', quad_game_hider_uniform_placement=False,\n",
    "             p_door_dropout=0.0,\n",
    "             n_rooms=4, random_room_number=True, prob_outside_walls=1.0,\n",
    "             n_lidar_per_agent=0, visualize_lidar=False, compress_lidar_scale=None,\n",
    "             hiders_together_radius=None, seekers_together_radius=None,\n",
    "             prep_fraction=0.4, prep_rem=False,\n",
    "             team_size_obs=False,\n",
    "             restrict_rect=None, penalize_objects_out=False,\n",
    "             n_food=0, food_radius=None, food_respawn_time=None, max_food_health=1,\n",
    "             food_together_radius=None, food_rew_type='selfish', eat_when_caught=False,\n",
    "             food_reward_scale=1.0, food_normal_centered=False, food_box_centered=False,\n",
    "             n_food_cluster=1):\n",
    "\n",
    "    grab_radius_multiplier = lock_grab_radius / box_size\n",
    "    lock_radius_multiplier = lock_grab_radius / box_size\n",
    "\n",
    "    env = Base(n_agents=n_hiders + n_seekers, n_frames=n_frames, horizon=horizon,\n",
    "               floor_size=floor_size, grid_size=grid_size,\n",
    "               action_lims=action_lims,\n",
    "               deterministic_mode=deterministic_mode)\n",
    "\n",
    "    if scenario == 'randomwalls':\n",
    "        env.add_module(RandomWalls(\n",
    "            grid_size=grid_size, num_rooms=n_rooms,\n",
    "            random_room_number=random_room_number, min_room_size=6,\n",
    "            door_size=door_size,\n",
    "            prob_outside_walls=prob_outside_walls, gen_door_obs=False))\n",
    "        box_placement_fn = uniform_placement\n",
    "        ramp_placement_fn = uniform_placement\n",
    "        cell_size = floor_size / grid_size\n",
    "\n",
    "        first_hider_placement = uniform_placement\n",
    "        if hiders_together_radius is not None:\n",
    "            htr_in_cells = np.ceil(hiders_together_radius / cell_size).astype(int)\n",
    "\n",
    "            env.metadata['hiders_together_radius'] = htr_in_cells\n",
    "\n",
    "            close_to_first_hider_placement = proximity_placement(\n",
    "                                                \"agent\", 0, \"hiders_together_radius\")\n",
    "\n",
    "            agent_placement_fn = [first_hider_placement] + \\\n",
    "                                 [close_to_first_hider_placement] * (n_hiders - 1)\n",
    "        else:\n",
    "            agent_placement_fn = [first_hider_placement] * n_hiders\n",
    "\n",
    "        first_seeker_placement = uniform_placement\n",
    "\n",
    "        if seekers_together_radius is not None:\n",
    "            str_in_cells = np.ceil(seekers_together_radius / cell_size).astype(int)\n",
    "\n",
    "            env.metadata['seekers_together_radius'] = str_in_cells\n",
    "\n",
    "            close_to_first_seeker_placement = proximity_placement(\n",
    "                                                \"agent\", n_hiders, \"seekers_together_radius\")\n",
    "\n",
    "            agent_placement_fn += [first_seeker_placement] + \\\n",
    "                                  [close_to_first_seeker_placement] * (n_seekers - 1)\n",
    "        else:\n",
    "            agent_placement_fn += [first_seeker_placement] * (n_seekers)\n",
    "\n",
    "    elif scenario == 'quad':\n",
    "        env.add_module(WallScenarios(grid_size=grid_size, door_size=door_size,\n",
    "                                     scenario=scenario, friction=other_friction,\n",
    "                                     p_door_dropout=p_door_dropout))\n",
    "        box_placement_fn = quad_placement\n",
    "        ramp_placement_fn = uniform_placement\n",
    "        hider_placement = uniform_placement if quad_game_hider_uniform_placement else quad_placement\n",
    "        agent_placement_fn = [hider_placement] * n_hiders + [outside_quad_placement] * n_seekers\n",
    "    else:\n",
    "        raise ValueError(f\"Scenario {scenario} not supported.\")\n",
    "\n",
    "    env.add_module(Agents(n_hiders + n_seekers,\n",
    "                          placement_fn=agent_placement_fn,\n",
    "                          color=[np.array((66., 235., 244., 255.)) / 255] * n_hiders + [np.array((240., 20., 50., 255.)) / 255] * n_seekers,\n",
    "                          friction=other_friction,\n",
    "                          polar_obs=polar_obs))\n",
    "    if np.max(n_boxes) > 0:\n",
    "        env.add_module(Boxes(n_boxes=n_boxes, placement_fn=box_placement_fn,\n",
    "                             friction=box_floor_friction, polar_obs=polar_obs,\n",
    "                             n_elongated_boxes=n_elongated_boxes,\n",
    "                             boxid_obs=boxid_obs, box_only_z_rot=box_only_z_rot))\n",
    "    if n_ramps > 0:\n",
    "        env.add_module(Ramps(n_ramps=n_ramps, placement_fn=ramp_placement_fn, friction=other_friction, polar_obs=polar_obs,\n",
    "                             pad_ramp_size=(np.max(n_elongated_boxes) > 0)))\n",
    "\n",
    "    # if box_floor_friction is not None:\n",
    "    #     env.add_module(FloorAttributes(friction=box_floor_friction))\n",
    "\n",
    "    keys_self = ['agent_q_qd', 'hider', 'prep_rem']\n",
    "    keys_mask_self = ['mask_aa_con']\n",
    "    keys_external = ['agent_qpos_qvel']\n",
    "    keys_copy = ['you_lock', 'team_lock', 'ramp_you_lock', 'ramp_team_lock']\n",
    "    keys_mask_external = []\n",
    "    # env = SplitMultiAgentActions(env)\n",
    "    if team_size_obs:\n",
    "        keys_self += ['team_size']\n",
    "    env = TeamMembership(env, jp.append(jp.zeros((n_hiders,)), jp.ones((n_seekers,))))\n",
    "    # env = AgentAgentObsMask2D(env)\n",
    "    env = AgentAgentContactMask2D(env)\n",
    "    hider_obs = jp.array([[1]] * n_hiders + [[0]] * n_seekers)\n",
    "    env = AddConstantObservationsWrapper(env, new_obs={'hider': hider_obs})\n",
    "    env = HideAndSeekRewardWrapper(env, n_hiders=n_hiders, n_seekers=n_seekers,\n",
    "                                   rew_type=rew_type)\n",
    "\n",
    "    env = PreparationPhase(env, prep_fraction=prep_fraction)\n",
    "\n",
    "    if np.max(n_boxes) > 0:\n",
    "        # env = AgentGeomObsMask2D(env, pos_obs_key='box_pos', mask_obs_key='mask_ab_obs',\n",
    "        #                          geom_idxs_obs_key='box_geom_idxs')\n",
    "        keys_external += ['box_obs']\n",
    "\n",
    "    # if lock_box and np.max(n_boxes) > 0:\n",
    "    #     env = LockObjWrapper(env, body_names=[f'moveable_box{i}' for i in range(np.max(n_boxes))],\n",
    "    #                          agent_idx_allowed_to_lock=np.arange(n_hiders+n_seekers),\n",
    "    #                          lock_type=lock_type, radius_multiplier=lock_radius_multiplier,\n",
    "    #                          obj_in_game_metadata_keys=[\"curr_n_boxes\"],\n",
    "    #                          agent_allowed_to_lock_keys=None if lock_out_of_vision else [\"mask_ab_obs\"])\n",
    "\n",
    "    if n_ramps > 0:\n",
    "        # if lock_ramp:\n",
    "        #     env = LockObjWrapper(env, body_names=[f'ramp{i}:ramp' for i in range(n_ramps)],\n",
    "        #                          agent_idx_allowed_to_lock=np.arange(n_hiders+n_seekers),\n",
    "        #                          lock_type=lock_type, ac_obs_prefix='ramp_',\n",
    "        #                          radius_multiplier=lock_radius_multiplier,\n",
    "        #                          obj_in_game_metadata_keys=['curr_n_ramps'],\n",
    "        #                          agent_allowed_to_lock_keys=None if lock_out_of_vision else [\"mask_ar_obs\"])\n",
    "        keys_external += ['ramp_obs']\n",
    "\n",
    "\n",
    "    if prep_rem:\n",
    "        env = TrackStatWrapper(env, np.max(n_boxes), n_ramps, n_food)\n",
    "    env = SplitObservations(env, keys_self + keys_mask_self, keys_copy=keys_copy, keys_self_matrices=keys_mask_self)\n",
    "    # env = SpoofEntityWrapper(env, np.max(n_boxes), ['box_obs', 'you_lock', 'team_lock', 'obj_lock'], ['mask_ab_obs'])\n",
    "\n",
    "    if max_n_agents is not None:\n",
    "        env = SpoofEntityWrapper(env, max_n_agents, ['agent_qpos_qvel', 'hider', 'prep_rem'], ['mask_aa_con'])\n",
    "    # env = LockAllWrapper(env, remove_object_specific_lock=True)\n",
    "    env = NoActionsInPrepPhase(env, np.arange(n_hiders, n_hiders + n_seekers))\n",
    "    env = ConcatenateObsWrapper(env, {'agent_q_qd': ['agent_q_qd', 'hider', 'prep_rem'],\n",
    "                                      'box_obs': ['box_obs'],\n",
    "                                      'ramp_obs': ['ramp_obs']})\n",
    "    # env = SelectKeysWrapper(env, keys_self=keys_self,\n",
    "    #                         keys_other=keys_external + keys_mask_self + keys_mask_external)\n",
    "                    \n",
    "    env = FlattenDictObsWrapper(env, n_hiders + n_seekers)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'door_obs': Array([[[3.1000001, 2.8      , 5.       , 3.1000001, 0.2      ,\n",
      "         0.2      ]],\n",
      "\n",
      "       [[3.1000001, 2.8      , 5.       , 3.1000001, 0.2      ,\n",
      "         0.2      ]],\n",
      "\n",
      "       [[3.1000001, 2.8      , 5.       , 3.1000001, 0.2      ,\n",
      "         0.2      ]],\n",
      "\n",
      "       [[3.1000001, 2.8      , 5.       , 3.1000001, 0.2      ,\n",
      "         0.2      ]]], dtype=float32), 'agent_q_qd_self': Array([[4.9996085 , 2.4471705 , 0.        , 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [3.269043  , 1.6792741 , 0.        , 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.77544785, 1.0054721 , 0.        , 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [4.8395805 , 3.3599887 , 0.        , 0.        , 0.        ,\n",
      "        0.        ]], dtype=float32), 'agent_q_qd': Array([[[4.8395805 , 3.3599887 , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.02499999],\n",
      "        [0.77544785, 1.0054721 , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.02499999],\n",
      "        [3.269043  , 1.6792741 , 0.        , 0.        , 0.        ,\n",
      "         0.        , 1.        , 0.02499999]],\n",
      "\n",
      "       [[4.9996085 , 2.4471705 , 0.        , 0.        , 0.        ,\n",
      "         0.        , 1.        , 0.02499999],\n",
      "        [4.8395805 , 3.3599887 , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.02499999],\n",
      "        [0.77544785, 1.0054721 , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.02499999]],\n",
      "\n",
      "       [[3.269043  , 1.6792741 , 0.        , 0.        , 0.        ,\n",
      "         0.        , 1.        , 0.02499999],\n",
      "        [4.9996085 , 2.4471705 , 0.        , 0.        , 0.        ,\n",
      "         0.        , 1.        , 0.02499999],\n",
      "        [4.8395805 , 3.3599887 , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.02499999]],\n",
      "\n",
      "       [[0.77544785, 1.0054721 , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.02499999],\n",
      "        [3.269043  , 1.6792741 , 0.        , 0.        , 0.        ,\n",
      "         0.        , 1.        , 0.02499999],\n",
      "        [4.9996085 , 2.4471705 , 0.        , 0.        , 0.        ,\n",
      "         0.        , 1.        , 0.02499999]]], dtype=float32), 'agent_pos': Array([[[4.9996085 , 2.4471705 , 0.        ],\n",
      "        [3.269043  , 1.6792741 , 0.        ],\n",
      "        [0.77544785, 1.0054721 , 0.        ],\n",
      "        [4.8395805 , 3.3599887 , 0.        ]],\n",
      "\n",
      "       [[4.9996085 , 2.4471705 , 0.        ],\n",
      "        [3.269043  , 1.6792741 , 0.        ],\n",
      "        [0.77544785, 1.0054721 , 0.        ],\n",
      "        [4.8395805 , 3.3599887 , 0.        ]],\n",
      "\n",
      "       [[4.9996085 , 2.4471705 , 0.        ],\n",
      "        [3.269043  , 1.6792741 , 0.        ],\n",
      "        [0.77544785, 1.0054721 , 0.        ],\n",
      "        [4.8395805 , 3.3599887 , 0.        ]],\n",
      "\n",
      "       [[4.9996085 , 2.4471705 , 0.        ],\n",
      "        [3.269043  , 1.6792741 , 0.        ],\n",
      "        [0.77544785, 1.0054721 , 0.        ],\n",
      "        [4.8395805 , 3.3599887 , 0.        ]]], dtype=float32), 'box_obs': Array([[[5.081342 , 1.9192322, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "         0.       , 0.       , 0.       , 0.       , 0.       ],\n",
      "        [3.5394607, 0.4585044, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "         0.       , 0.       , 0.       , 0.       , 0.       ]],\n",
      "\n",
      "       [[5.081342 , 1.9192322, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "         0.       , 0.       , 0.       , 0.       , 0.       ],\n",
      "        [3.5394607, 0.4585044, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "         0.       , 0.       , 0.       , 0.       , 0.       ]],\n",
      "\n",
      "       [[5.081342 , 1.9192322, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "         0.       , 0.       , 0.       , 0.       , 0.       ],\n",
      "        [3.5394607, 0.4585044, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "         0.       , 0.       , 0.       , 0.       , 0.       ]],\n",
      "\n",
      "       [[5.081342 , 1.9192322, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "         0.       , 0.       , 0.       , 0.       , 0.       ],\n",
      "        [3.5394607, 0.4585044, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "         0.       , 0.       , 0.       , 0.       , 0.       ]]],      dtype=float32), 'box_angle': Array([[[0., 0., 0.],\n",
      "        [0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0.],\n",
      "        [0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0.],\n",
      "        [0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0.],\n",
      "        [0., 0., 0.]]], dtype=float32), 'box_pos': Array([[[5.081342 , 1.9192322, 0.25     ],\n",
      "        [3.5394607, 0.4585044, 0.25     ]],\n",
      "\n",
      "       [[5.081342 , 1.9192322, 0.25     ],\n",
      "        [3.5394607, 0.4585044, 0.25     ]],\n",
      "\n",
      "       [[5.081342 , 1.9192322, 0.25     ],\n",
      "        [3.5394607, 0.4585044, 0.25     ]],\n",
      "\n",
      "       [[5.081342 , 1.9192322, 0.25     ],\n",
      "        [3.5394607, 0.4585044, 0.25     ]]], dtype=float32), 'ramp_obs': Array([[[3.066983 , 4.3378143, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "         0.       , 0.       , 0.       , 0.       , 0.       ]],\n",
      "\n",
      "       [[3.066983 , 4.3378143, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "         0.       , 0.       , 0.       , 0.       , 0.       ]],\n",
      "\n",
      "       [[3.066983 , 4.3378143, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "         0.       , 0.       , 0.       , 0.       , 0.       ]],\n",
      "\n",
      "       [[3.066983 , 4.3378143, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "         0.       , 0.       , 0.       , 0.       , 0.       ]]],      dtype=float32), 'ramp_angle': Array([[[0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0.]]], dtype=float32), 'ramp_q': Array([[[3.066983 , 4.3378143, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       ]],\n",
      "\n",
      "       [[3.066983 , 4.3378143, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       ]],\n",
      "\n",
      "       [[3.066983 , 4.3378143, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       ]],\n",
      "\n",
      "       [[3.066983 , 4.3378143, 0.25     , 1.       , 1.       ,\n",
      "         1.       , 0.       , 0.       , 0.       ]]], dtype=float32), 'team_size': Array([[[2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2]],\n",
      "\n",
      "       [[2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2]],\n",
      "\n",
      "       [[2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2]],\n",
      "\n",
      "       [[2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2]]], dtype=int32), 'mask_aa_con': Array([[ True, False,  True],\n",
      "       [ True,  True,  True],\n",
      "       [ True, False, False],\n",
      "       [False,  True,  True]], dtype=bool), 'hider_self': Array([[1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0]], dtype=int32), 'hider': Array([[[0],\n",
      "        [0],\n",
      "        [1]],\n",
      "\n",
      "       [[1],\n",
      "        [0],\n",
      "        [0]],\n",
      "\n",
      "       [[1],\n",
      "        [1],\n",
      "        [0]],\n",
      "\n",
      "       [[0],\n",
      "        [1],\n",
      "        [1]]], dtype=int32), 'prep_rem_self': Array([[0.02499999],\n",
      "       [0.02499999],\n",
      "       [0.02499999],\n",
      "       [0.02499999]], dtype=float32), 'prep_rem': Array([[[0.02499999],\n",
      "        [0.02499999],\n",
      "        [0.02499999]],\n",
      "\n",
      "       [[0.02499999],\n",
      "        [0.02499999],\n",
      "        [0.02499999]],\n",
      "\n",
      "       [[0.02499999],\n",
      "        [0.02499999],\n",
      "        [0.02499999]],\n",
      "\n",
      "       [[0.02499999],\n",
      "        [0.02499999],\n",
      "        [0.02499999]]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "test_env = make_env(random_key)\n",
    "\n",
    "test_env.gen_sys(seed)\n",
    "\n",
    "# state = jax.jit(test_env.reset)(random_key)\n",
    "state = test_env.reset(random_key)\n",
    "print(state.d_obs)\n",
    "# print(state.obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomise_action(act, random_key):\n",
    "    random_key, sub_key = random.split(random_key)\n",
    "    return random.uniform(random_key, shape=act.shape, minval=-0.25, maxval=0.25), random_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_step_fn = jax.jit(test_env.step)\n",
    "act_size = test_env.sys.act_size()\n",
    "\n",
    "act = jp.zeros(shape=(test_env.n_agents, act_size // test_env.n_agents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_obs:  {'door_obs': Array([[3.1000001, 2.8      , 5.       , 3.1000001, 0.2      , 0.2      ]],      dtype=float32), 'agent_q_qd': Traced<ShapedArray(float32[4,6])>with<DynamicJaxprTrace(level=1/0)>, 'agent_pos': Traced<ShapedArray(float32[4,3])>with<DynamicJaxprTrace(level=1/0)>, 'box_obs': Traced<ShapedArray(float32[2,15])>with<DynamicJaxprTrace(level=1/0)>, 'box_angle': Traced<ShapedArray(float32[2,3])>with<DynamicJaxprTrace(level=1/0)>, 'box_pos': Traced<ShapedArray(float32[2,3])>with<DynamicJaxprTrace(level=1/0)>, 'ramp_obs': Traced<ShapedArray(float32[1,15])>with<DynamicJaxprTrace(level=1/0)>, 'ramp_angle': Traced<ShapedArray(float32[1,3])>with<DynamicJaxprTrace(level=1/0)>, 'ramp_q': Traced<ShapedArray(float32[1,9])>with<DynamicJaxprTrace(level=1/0)>}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     rollout\u001b[39m.\u001b[39mappend(state\u001b[39m.\u001b[39mpipeline_state)\n\u001b[1;32m      6\u001b[0m     \u001b[39m# state = test_env.step(state, act)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     state \u001b[39m=\u001b[39m jit_step_fn(state, act)\n\u001b[1;32m      9\u001b[0m html\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39magents.html\u001b[39m\u001b[39m'\u001b[39m, test_env\u001b[39m.\u001b[39msys, rollout)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/mae_envs/wrappers/util.py:120\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, state, action):\n\u001b[1;32m    119\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns a modified observation using :meth:`self.observation` after calling :meth:`env.step`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     dst_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(state, action)\n\u001b[1;32m    121\u001b[0m     d_obs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation(state)\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m dst_state\u001b[39m.\u001b[39mreplace(d_obs\u001b[39m=\u001b[39md_obs)\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/mae_envs/wrappers/util.py:120\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, state, action):\n\u001b[1;32m    119\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns a modified observation using :meth:`self.observation` after calling :meth:`env.step`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     dst_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(state, action)\n\u001b[1;32m    121\u001b[0m     d_obs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation(state)\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m dst_state\u001b[39m.\u001b[39mreplace(d_obs\u001b[39m=\u001b[39md_obs)\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/mae_envs/wrappers/prep_phase.py:73\u001b[0m, in \u001b[0;36mNoActionsInPrepPhase.step\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, state, action):\n\u001b[0;32m---> 73\u001b[0m     dst_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(state, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction(state, action))\n\u001b[1;32m     74\u001b[0m     \u001b[39mreturn\u001b[39;00m dst_state\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/mae_envs/wrappers/util.py:120\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, state, action):\n\u001b[1;32m    119\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns a modified observation using :meth:`self.observation` after calling :meth:`env.step`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     dst_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(state, action)\n\u001b[1;32m    121\u001b[0m     d_obs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation(state)\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m dst_state\u001b[39m.\u001b[39mreplace(d_obs\u001b[39m=\u001b[39md_obs)\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/mae_envs/wrappers/prep_phase.py:45\u001b[0m, in \u001b[0;36mPreparationPhase.step\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, state, action):\n\u001b[0;32m---> 45\u001b[0m     dst_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(state, action)\n\u001b[1;32m     46\u001b[0m     rew \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward(dst_state)\n\u001b[1;32m     48\u001b[0m     info \u001b[39m=\u001b[39m dst_state\u001b[39m.\u001b[39minfo\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/mae_envs/envs/hide_and_seek.py:136\u001b[0m, in \u001b[0;36mHideAndSeekRewardWrapper.step\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, state, action):\n\u001b[0;32m--> 136\u001b[0m     dst_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(state, action)\n\u001b[1;32m    137\u001b[0m     d_obs \u001b[39m=\u001b[39m dst_state\u001b[39m.\u001b[39md_obs\n\u001b[1;32m    139\u001b[0m     this_rew \u001b[39m=\u001b[39m jp\u001b[39m.\u001b[39mones((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_agents,))\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/mae_envs/wrappers/util.py:120\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, state, action):\n\u001b[1;32m    119\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns a modified observation using :meth:`self.observation` after calling :meth:`env.step`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     dst_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(state, action)\n\u001b[1;32m    121\u001b[0m     d_obs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation(state)\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m dst_state\u001b[39m.\u001b[39mreplace(d_obs\u001b[39m=\u001b[39md_obs)\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/mae_envs/wrappers/util.py:121\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a modified observation using :meth:`self.observation` after calling :meth:`env.step`.\"\"\"\u001b[39;00m\n\u001b[1;32m    120\u001b[0m dst_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mstep(state, action)\n\u001b[0;32m--> 121\u001b[0m d_obs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobservation(state)\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m dst_state\u001b[39m.\u001b[39mreplace(d_obs\u001b[39m=\u001b[39md_obs)\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/mae_envs/wrappers/line_of_sight.py:23\u001b[0m, in \u001b[0;36mAgentAgentContactMask2D.observation\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m# print('AA d_obs: ', d_obs)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m agent_pos2d \u001b[39m=\u001b[39m d_obs[\u001b[39m'\u001b[39m\u001b[39magent_pos\u001b[39m\u001b[39m'\u001b[39m][:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 23\u001b[0m contact_mask \u001b[39m=\u001b[39m caught(agent_pos2d, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistance_threshold)\n\u001b[1;32m     25\u001b[0m d_obs[\u001b[39m'\u001b[39m\u001b[39mmask_aa_con\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m contact_mask\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m d_obs\n",
      "File \u001b[0;32m~/dev/imperial/FYP/MAax/mae_envs/util/vision.py:15\u001b[0m, in \u001b[0;36mcaught\u001b[0;34m(origin_pts, threshold_dist)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mComputes whether agents are within a threhsold distance of each other in 2D space\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m    contact_mask (jp.ndarray): array with shape (n_agents, n_agents) of bools\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(origin_pts, jp\u001b[39m.\u001b[39mndarray)\n\u001b[0;32m---> 15\u001b[0m \u001b[39massert\u001b[39;00m origin_pts\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[39m#Initialise contact mask\u001b[39;00m\n\u001b[1;32m     18\u001b[0m contact_mask \u001b[39m=\u001b[39m jp\u001b[39m.\u001b[39mzeros((origin_pts\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], origin_pts\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rollout = []\n",
    "\n",
    "for i in range(horizon):\n",
    "    act, random_key = jax.lax.cond(i % 50 == 0, randomise_action, lambda x, y: (x, y), act, random_key)\n",
    "    rollout.append(state.pipeline_state)\n",
    "    # state = test_env.step(state, act)\n",
    "    state = jit_step_fn(state, act)\n",
    "\n",
    "html.save('agents.html', test_env.sys, rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "# def play_step_fn(state: State, act: Action, random_key: RNGKey, index: int):\n",
    "#     act, random_key = jax.lax.cond(index % 50 == 0, randomise_action, lambda x, y: (x, y), act, random_key)\n",
    "#     state = jit_step_fn(state, act)\n",
    "#     return state, act, random_key, index + 1, state.pipeline_state\n",
    "\n",
    "# def scan_play_step_fn(\n",
    "#     carry: Tuple[State, Action, RNGKey, int], unused_arg: Any\n",
    "# ) ->Tuple[Tuple[State, RNGKey, int], PipelineState]:\n",
    "#     state, act, random_key, index, p_states = play_step_fn(*carry)\n",
    "#     return (state, act, random_key, index), p_states\n",
    "    \n",
    "\n",
    "# (dst_state, dst_act, key, index), rollout = jax.lax.scan(scan_play_step_fn, (state, act, random_key, 0), None, length=horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states_list = []\n",
    "# print(dst_state.info)\n",
    "# print(dst_state.reward)\n",
    "\n",
    "# for i in range(horizon):\n",
    "#     s = jax.tree_util.tree_map(lambda x: x[i], rollout)\n",
    "#     states_list.append(s)\n",
    "\n",
    "\n",
    "# html.save('agents.html', test_env.sys, states_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('maax_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d286b5a782650f2d9ae8fe3e234d77a318fcb8a23bb1ca21ad01d6849611a0dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
