{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('/Users/tom/dev/imperial/FYP/MAax/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldgen import Floor, WorldBuilder, WorldParams\n",
    "from mae_envs.modules.agents import Agents\n",
    "from mae_envs.modules.walls import RandomWalls, WallScenarios\n",
    "from mae_envs.modules.world import FloorAttributes, WorldConstants\n",
    "from mae_envs.modules.objects import Boxes, Cylinders, LidarSites, Ramps\n",
    "from mae_envs.modules.util import uniform_placement, center_placement, close_to_other_object_placement\n",
    "from mae_envs.envs.hide_and_seek import quadrant_placement, outside_quadrant_placement, HideAndSeekRewardWrapper, TrackStatWrapper\n",
    "from maax.envs.base import Base\n",
    "from mae_envs.wrappers.multi_agent import (SplitMultiAgentActions,\n",
    "                                           SplitObservations, SelectKeysWrapper)\n",
    "from mae_envs.wrappers.util import (ConcatenateObsWrapper,\n",
    "                                    MaskActionWrapper, SpoofEntityWrapper,\n",
    "                                    AddConstantObservationsWrapper, MWrapper)\n",
    "from mae_envs.wrappers.manipulation import (LockObjWrapper, LockAllWrapper)\n",
    "from mae_envs.wrappers.lidar import Lidar\n",
    "from mae_envs.wrappers.line_of_sight import (AgentAgentObsMask2D, AgentAgentContactMask2D,\n",
    "                                            AgentGeomObsMask2D, AgentSiteObsMask2D)\n",
    "from mae_envs.wrappers.prep_phase import (PreparationPhase, NoActionsInPrepPhase,\n",
    "                                          MaskPrepPhaseAction)\n",
    "from mae_envs.wrappers.limit_mvmnt import RestrictAgentsRect\n",
    "from mae_envs.wrappers.team import TeamMembership\n",
    "from mae_envs.wrappers.food import FoodHealthWrapper, AlwaysEatWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brax\n",
    "import numpy as np\n",
    "from brax.io import mjcf, html\n",
    "from maax.envs.base import Base\n",
    "from mae_envs.util.types import RNGKey, PipelineState, Action\n",
    "from brax.generalized import pipeline\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "\n",
    "from jax import random\n",
    "\n",
    "from IPython.display import HTML, clear_output\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maax.envs.base import State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 16\n",
    "horizon = 1000\n",
    "n_frames = 1\n",
    "random_key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(deterministic_mode=False,\n",
    "             floor_size=6.0, grid_size=30, door_size=2,\n",
    "             n_hiders=1, n_seekers=1, max_n_agents=None,\n",
    "             n_boxes=2, n_ramps=1, n_elongated_boxes=0,\n",
    "             rand_num_elongated_boxes=False, n_min_boxes=None,\n",
    "             box_size=0.5, boxid_obs=False, box_only_z_rot=True,\n",
    "             rew_type='joint_zero_sum',\n",
    "             lock_box=True, grab_box=True, lock_ramp=True,\n",
    "             lock_type='any_lock_specific',\n",
    "             lock_grab_radius=0.25, lock_out_of_vision=True, grab_exclusive=False,\n",
    "             grab_out_of_vision=False, grab_selective=False,\n",
    "             box_floor_friction=0.2, other_friction=0.01, gravity=[0, 0, -50],\n",
    "             action_lims=(-0.9, 0.9), polar_obs=True,\n",
    "             scenario='quadrant', quadrant_game_hider_uniform_placement=False,\n",
    "             p_door_dropout=0.0,\n",
    "             n_rooms=4, random_room_number=True, prob_outside_walls=1.0,\n",
    "             n_lidar_per_agent=0, visualize_lidar=False, compress_lidar_scale=None,\n",
    "             hiders_together_radius=None, seekers_together_radius=None,\n",
    "             prep_fraction=0.1, prep_obs=False,\n",
    "             team_size_obs=False,\n",
    "             restrict_rect=None, penalize_objects_out=False,\n",
    "             n_food=0, food_radius=None, food_respawn_time=None, max_food_health=1,\n",
    "             food_together_radius=None, food_rew_type='selfish', eat_when_caught=False,\n",
    "             food_reward_scale=1.0, food_normal_centered=False, food_box_centered=False,\n",
    "             n_food_cluster=1):\n",
    "\n",
    "    grab_radius_multiplier = lock_grab_radius / box_size\n",
    "    lock_radius_multiplier = lock_grab_radius / box_size\n",
    "\n",
    "    env = Base(n_agents=n_hiders + n_seekers, n_frames=n_frames, horizon=horizon,\n",
    "               floor_size=floor_size, grid_size=grid_size,\n",
    "               action_lims=action_lims,\n",
    "               deterministic_mode=deterministic_mode)\n",
    "\n",
    "    if scenario == 'randomwalls':\n",
    "        env.add_module(RandomWalls(\n",
    "            grid_size=grid_size, num_rooms=n_rooms,\n",
    "            random_room_number=random_room_number, min_room_size=6,\n",
    "            door_size=door_size,\n",
    "            prob_outside_walls=prob_outside_walls, gen_door_obs=False))\n",
    "        box_placement_fn = uniform_placement\n",
    "        ramp_placement_fn = uniform_placement\n",
    "        cell_size = floor_size / grid_size\n",
    "\n",
    "        first_hider_placement = uniform_placement\n",
    "        if hiders_together_radius is not None:\n",
    "            htr_in_cells = np.ceil(hiders_together_radius / cell_size).astype(int)\n",
    "\n",
    "            env.metadata['hiders_together_radius'] = htr_in_cells\n",
    "\n",
    "            close_to_first_hider_placement = close_to_other_object_placement(\n",
    "                                                \"agent\", 0, \"hiders_together_radius\")\n",
    "\n",
    "            agent_placement_fn = [first_hider_placement] + \\\n",
    "                                 [close_to_first_hider_placement] * (n_hiders - 1)\n",
    "        else:\n",
    "            agent_placement_fn = [first_hider_placement] * n_hiders\n",
    "\n",
    "        first_seeker_placement = uniform_placement\n",
    "\n",
    "        if seekers_together_radius is not None:\n",
    "            str_in_cells = np.ceil(seekers_together_radius / cell_size).astype(int)\n",
    "\n",
    "            env.metadata['seekers_together_radius'] = str_in_cells\n",
    "\n",
    "            close_to_first_seeker_placement = close_to_other_object_placement(\n",
    "                                                \"agent\", n_hiders, \"seekers_together_radius\")\n",
    "\n",
    "            agent_placement_fn += [first_seeker_placement] + \\\n",
    "                                  [close_to_first_seeker_placement] * (n_seekers - 1)\n",
    "        else:\n",
    "            agent_placement_fn += [first_seeker_placement] * (n_seekers)\n",
    "\n",
    "    elif scenario == 'quadrant':\n",
    "        env.add_module(WallScenarios(grid_size=grid_size, door_size=door_size,\n",
    "                                     scenario=scenario, friction=other_friction,\n",
    "                                     p_door_dropout=p_door_dropout))\n",
    "        box_placement_fn = quadrant_placement\n",
    "        ramp_placement_fn = uniform_placement\n",
    "        hider_placement = uniform_placement if quadrant_game_hider_uniform_placement else quadrant_placement\n",
    "        agent_placement_fn = [hider_placement] * n_hiders + [outside_quadrant_placement] * n_seekers\n",
    "    else:\n",
    "        raise ValueError(f\"Scenario {scenario} not supported.\")\n",
    "\n",
    "    env.add_module(Agents(n_hiders + n_seekers,\n",
    "                          placement_fn=agent_placement_fn,\n",
    "                          color=[np.array((66., 235., 244., 255.)) / 255] * n_hiders + [(1., 0., 0., 1.)] * n_seekers,\n",
    "                          friction=other_friction,\n",
    "                          polar_obs=polar_obs))\n",
    "    if np.max(n_boxes) > 0:\n",
    "        env.add_module(Boxes(n_boxes=n_boxes, placement_fn=box_placement_fn,\n",
    "                             friction=box_floor_friction, polar_obs=polar_obs,\n",
    "                             n_elongated_boxes=n_elongated_boxes,\n",
    "                             boxid_obs=boxid_obs, box_only_z_rot=box_only_z_rot))\n",
    "    if n_ramps > 0:\n",
    "        env.add_module(Ramps(n_ramps=n_ramps, placement_fn=ramp_placement_fn, friction=other_friction, polar_obs=polar_obs,\n",
    "                             pad_ramp_size=(np.max(n_elongated_boxes) > 0)))\n",
    "\n",
    "    if box_floor_friction is not None:\n",
    "        env.add_module(FloorAttributes(friction=box_floor_friction))\n",
    "\n",
    "    keys_self = ['agent_qpos_qvel', 'hider', 'prep_obs']\n",
    "    keys_mask_self = ['mask_aa_con']\n",
    "    keys_external = ['agent_qpos_qvel']\n",
    "    keys_copy = ['you_lock', 'team_lock', 'ramp_you_lock', 'ramp_team_lock']\n",
    "    keys_mask_external = []\n",
    "    # env = SplitMultiAgentActions(env)\n",
    "    if team_size_obs:\n",
    "        keys_self += ['team_size']\n",
    "    env = TeamMembership(env, np.append(np.zeros((n_hiders,)), np.ones((n_seekers,))))\n",
    "    # env = AgentAgentObsMask2D(env)\n",
    "    env = AgentAgentContactMask2D(env)\n",
    "    hider_obs = np.array([[1]] * n_hiders + [[0]] * n_seekers)\n",
    "    env = AddConstantObservationsWrapper(env, new_obs={'hider': hider_obs})\n",
    "    env = HideAndSeekRewardWrapper(env, n_hiders=n_hiders, n_seekers=n_seekers,\n",
    "                                   rew_type=rew_type)\n",
    "\n",
    "    env = PreparationPhase(env, prep_fraction=prep_fraction)\n",
    "\n",
    "    if np.max(n_boxes) > 0:\n",
    "        # env = AgentGeomObsMask2D(env, pos_obs_key='box_pos', mask_obs_key='mask_ab_obs',\n",
    "        #                          geom_idxs_obs_key='box_geom_idxs')\n",
    "        keys_external += ['box_obs']\n",
    "\n",
    "    # if lock_box and np.max(n_boxes) > 0:\n",
    "    #     env = LockObjWrapper(env, body_names=[f'moveable_box{i}' for i in range(np.max(n_boxes))],\n",
    "    #                          agent_idx_allowed_to_lock=np.arange(n_hiders+n_seekers),\n",
    "    #                          lock_type=lock_type, radius_multiplier=lock_radius_multiplier,\n",
    "    #                          obj_in_game_metadata_keys=[\"curr_n_boxes\"],\n",
    "    #                          agent_allowed_to_lock_keys=None if lock_out_of_vision else [\"mask_ab_obs\"])\n",
    "\n",
    "    if n_ramps > 0:\n",
    "        # if lock_ramp:\n",
    "        #     env = LockObjWrapper(env, body_names=[f'ramp{i}:ramp' for i in range(n_ramps)],\n",
    "        #                          agent_idx_allowed_to_lock=np.arange(n_hiders+n_seekers),\n",
    "        #                          lock_type=lock_type, ac_obs_prefix='ramp_',\n",
    "        #                          radius_multiplier=lock_radius_multiplier,\n",
    "        #                          obj_in_game_metadata_keys=['curr_n_ramps'],\n",
    "        #                          agent_allowed_to_lock_keys=None if lock_out_of_vision else [\"mask_ar_obs\"])\n",
    "        keys_external += ['ramp_obs']\n",
    "\n",
    "\n",
    "    if prep_obs:\n",
    "        env = TrackStatWrapper(env, np.max(n_boxes), n_ramps, n_food)\n",
    "    env = SplitObservations(env, keys_self + keys_mask_self, keys_copy=keys_copy, keys_self_matrices=keys_mask_self)\n",
    "    # env = SpoofEntityWrapper(env, np.max(n_boxes), ['box_obs', 'you_lock', 'team_lock', 'obj_lock'], ['mask_ab_obs'])\n",
    "\n",
    "    # if max_n_agents is not None:\n",
    "    #     env = SpoofEntityWrapper(env, max_n_agents, ['agent_qpos_qvel', 'hider', 'prep_obs'], ['mask_aa_obs'])\n",
    "    # env = LockAllWrapper(env, remove_object_specific_lock=True)\n",
    "    env = NoActionsInPrepPhase(env, np.arange(n_hiders, n_hiders + n_seekers))\n",
    "    # env = ConcatenateObsWrapper(env, {'agent_qpos_qvel': ['agent_qpos_qvel'],\n",
    "    #                                   'box_obs': ['box_obs'],\n",
    "    #                                   'ramp_obs': ['ramp_obs']})\n",
    "    env = SelectKeysWrapper(env, keys_self=keys_self,\n",
    "                            keys_other=keys_external + keys_mask_self + keys_mask_external)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = make_env(random_key)\n",
    "\n",
    "test_env.gen_sys(seed)\n",
    "\n",
    "state = jax.jit(test_env.reset)(random_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomise_action(act, random_key):\n",
    "    random_key, sub_key = random.split(random_key)\n",
    "    return random.uniform(random_key, shape=act.shape, minval=-0.25, maxval=0.25), random_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_step_fn = jax.jit(test_env.step)\n",
    "act_size = test_env.sys.act_size()\n",
    "\n",
    "act = jp.zeros(shape=(test_env.n_agents, act_size // test_env.n_agents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre rollout info {'in_prep_phase': Array(True, dtype=bool)}\n",
      "Action before:  Traced<ShapedArray(float32[2,3])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Action after:  Traced<ShapedArray(float32[2,3])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Reward:  Traced<ShapedArray(float32[2])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Step counter:  1\n",
      "Prep time:  100.0\n",
      "In prep phase:  Traced<ShapedArray(bool[])>with<DynamicJaxprTrace(level=1/0)>\n"
     ]
    }
   ],
   "source": [
    "rollout = []\n",
    "\n",
    "print('Pre rollout info', state.info)\n",
    "for i in range(horizon):\n",
    "    act, random_key = jax.lax.cond(i % 50 == 0, randomise_action, lambda x, y: (x, y), act, random_key)\n",
    "    rollout.append(state.pipeline_state)\n",
    "    # state = test_env.step(state, act)\n",
    "    state = jit_step_fn(state, act)\n",
    "\n",
    "html.save('agents.html', test_env.sys, rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.9921125e-02  1.5000001e-01  1.5000001e-01  4.9907938e-02\n",
      "  5.8499999e+00  1.5000001e-01  1.5000001e-01  5.8499999e+00\n",
      "  3.0500000e+00  1.5000001e-01  3.1500001e+00  3.0500000e+00\n",
      "  5.3499999e+00  3.0500000e+00  5.5500655e+00  1.7798762e+00\n",
      " -1.2624390e+03  3.4625921e+00  3.9048047e+00  0.0000000e+00\n",
      "  5.3455887e+00  8.9175218e-01  2.4999288e-01  1.0000000e+00\n",
      "  9.2356631e-06  5.7887610e-06  7.3151564e-06  3.5483999e+00\n",
      "  1.9233425e+00  2.4999322e-01  1.0000000e+00  4.3888308e-06\n",
      "  5.9265412e-06  2.5288111e-06  2.6488395e+00  2.2664154e+00\n",
      "  2.4965034e-01  5.5963337e-01  1.5757349e-04 -5.7901669e-04\n",
      " -8.2874006e-01]\n"
     ]
    }
   ],
   "source": [
    "print(state.pipeline_state.q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "# def play_step_fn(state: State, act: Action, random_key: RNGKey, index: int):\n",
    "#     act, random_key = jax.lax.cond(index % 50 == 0, randomise_action, lambda x, y: (x, y), act, random_key)\n",
    "#     state = jit_step_fn(state, act)\n",
    "#     return state, act, random_key, index + 1, state.pipeline_state\n",
    "\n",
    "# def scan_play_step_fn(\n",
    "#     carry: Tuple[State, Action, RNGKey, int], unused_arg: Any\n",
    "# ) ->Tuple[Tuple[State, RNGKey, int], PipelineState]:\n",
    "#     state, act, random_key, index, p_states = play_step_fn(*carry)\n",
    "#     return (state, act, random_key, index), p_states\n",
    "    \n",
    "\n",
    "# (dst_state, dst_act, key, index), rollout = jax.lax.scan(scan_play_step_fn, (state, act, random_key, 0), None, length=horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states_list = []\n",
    "# print(dst_state.info)\n",
    "# print(dst_state.reward)\n",
    "\n",
    "# for i in range(horizon):\n",
    "#     s = jax.tree_util.tree_map(lambda x: x[i], rollout)\n",
    "#     states_list.append(s)\n",
    "\n",
    "\n",
    "# html.save('agents.html', test_env.sys, states_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('maax_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d286b5a782650f2d9ae8fe3e234d77a318fcb8a23bb1ca21ad01d6849611a0dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
